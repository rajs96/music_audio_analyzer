{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3edff3e-c884-406d-a3be-a7da25a22cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import time, uuid, hashlib\n",
    "import ray\n",
    "\n",
    "from data_classes import InstrumentDetectJob\n",
    "\n",
    "def jobs_from_audio_dir(audio_dir: str) -> list[InstrumentDetectJob]:\n",
    "    audio_dir = Path(audio_dir)\n",
    "    created_at = int(time.time())\n",
    "    job_id = f\"job_{uuid.uuid4().hex[:12]}\"\n",
    "\n",
    "    jobs: list[InstrumentDetectJob] = []\n",
    "    for p in sorted(audio_dir.glob(\"*\")):\n",
    "        if not p.is_file():\n",
    "            continue\n",
    "\n",
    "        audio_bytes = p.read_bytes()\n",
    "        song_id = f\"trk_{uuid.uuid4().hex[:12]}\"\n",
    "        song_hash = hashlib.sha256(audio_bytes).hexdigest()\n",
    "        audio_ref = ray.put(audio_bytes)\n",
    "\n",
    "        jobs.append(\n",
    "            InstrumentDetectJob(\n",
    "                job_id=job_id,\n",
    "                created_at=created_at,\n",
    "                song_id=song_id,\n",
    "                song_hash=song_hash,\n",
    "                audio_ref=audio_ref,\n",
    "                filename=p.name,\n",
    "            )\n",
    "        )\n",
    "    return jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "350299d3-d4af-4502-82df-7568e5138268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-21 14:14:15,875\tINFO worker.py:2007 -- Started a local Ray instance.\n",
      "/home/ubuntu/venv/qwen-env/lib/python3.12/site-packages/ray/_private/worker.py:2046: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "jobs = jobs_from_audio_dir(\"audio_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73e49087-06eb-4a86-afee-fbf523931e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List\n",
    "from load_qwen import load_model_and_processor\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import io\n",
    "import tempfile\n",
    "import torchaudio\n",
    "\n",
    "class InstrumentDetector(ABC):\n",
    "    \"\"\"\n",
    "    Abstract base class for instrument detection models.\n",
    "\n",
    "    All instrument detector implementations must provide both `process` and `predict` methods.\n",
    "    \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def process(self, audio_bytes_list) -> List[str]:\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def predict(self, audio_bytes_list) -> List[str]:\n",
    "        \"\"\" \"\"\"\n",
    "        pass\n",
    "\n",
    "\n",
    "class QwenInstrumentDetector(InstrumentDetector):\n",
    "    def __init__(self):\n",
    "        self.model_name = \"Qwen/Qwen3-Omni-30B-A3B-Thinking\"\n",
    "        self.model, self.processor = load_model_and_processor(self.model_name)\n",
    "\n",
    "    def process(self, jobs: list[InstrumentDetectJob]) -> List[str]:\n",
    "        waveform_audios = []\n",
    "        for job in jobs:\n",
    "            suffix = job.filename.split(\".\")[-1]\n",
    "            audio_bytes = ray.get(job.audio_ref)\n",
    "            waveform_audios.append(self.decode_audio_bytes_to_waveform(audio_bytes, suffix, target_sr=16000))\n",
    "\n",
    "        return waveform_audios\n",
    "\n",
    "    def predict(self, audio_ref_list) -> List[str]:\n",
    "        pass\n",
    "\n",
    "    def decode_audio_bytes_to_waveform(self, audio_bytes: bytes, suffix: str, target_sr: int = 16000) -> np.ndarray:\n",
    "        # Write bytes to a temp file so ffmpeg backend can decode it\n",
    "        with tempfile.NamedTemporaryFile(suffix=suffix, delete=True) as f:\n",
    "            f.write(audio_bytes)\n",
    "            f.flush()\n",
    "    \n",
    "            wav, sr = torchaudio.load(f.name)  # wav: (channels, time)\n",
    "    \n",
    "        # Convert to mono (optional, but typical)\n",
    "        if wav.shape[0] > 1:\n",
    "            wav = wav.mean(dim=0, keepdim=True)\n",
    "    \n",
    "        # Resample to target_sr\n",
    "        if sr != target_sr:\n",
    "            wav = torchaudio.functional.resample(wav, orig_freq=sr, new_freq=target_sr)\n",
    "    \n",
    "        return wav.squeeze(0).numpy().astype(\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a39e3aa4-bba6-4060-82f9-c3052e967bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unrecognized keys in `rope_scaling` for 'rope_type'='default': {'mrope_section', 'mrope_interleaved', 'interleaved'}\n",
      "You are attempting to use Flash Attention 2 without specifying a torch dtype. This might lead to unexpected behaviour\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d50d5c7201d4828bb904d0fb1564f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    }
   ],
   "source": [
    "detector = QwenInstrumentDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77b19ab1-536e-4192-82b1-c2af16f66931",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_form_list = detector.process(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70efafd3-a0fe-42c2-acdc-2809e1f06829",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-1.4878102e-05, -2.9345811e-05, -2.9599703e-05, ...,\n",
       "         0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "       shape=(4277974,), dtype=float32),\n",
       " array([2.4055022e-05, 4.3867341e-05, 3.3767825e-05, ..., 3.7365222e-05,\n",
       "        3.2300261e-05, 3.1887150e-05], shape=(4278416,), dtype=float32),\n",
       " array([ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "        -1.4919133e-05, -1.6012546e-05, -1.2392791e-05],\n",
       "       shape=(4203416,), dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(pid=38956)\u001b[0m [2025-12-21 14:14:48,073 E 38956 39157] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n",
      "[2025-12-21 14:14:48,660 E 38668 38954] core_worker_process.cc:842: Failed to establish connection to the metrics exporter agent. Metrics will not be exported. Exporter agent status: RpcError: Running out of retries to initialize the metrics agent. rpc_code: 14\n"
     ]
    }
   ],
   "source": [
    "wave_form_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efab910-737a-49f4-bf6f-df9e14edf8a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
