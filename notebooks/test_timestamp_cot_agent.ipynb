{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrument Detection with Timestamps - 3-Step CoT\n",
    "\n",
    "Chain of thought:\n",
    "1. Layer Analysis (background/middleground/foreground)\n",
    "2. Timestamp Analysis (when instruments enter/exit)\n",
    "3. Structured JSON Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import json\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "\n",
    "from src.data.qwen_omni import QwenOmniCoTDataset\n",
    "from src.models import load_model_and_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "MODEL_NAME = \"Qwen/Qwen3-Omni-30B-A3B-Instruct\"\n",
    "AUDIO_DIR = \"../audio_files\"\n",
    "DTYPE = torch.bfloat16\n",
    "DEVICE = \"cuda\"\n",
    "MAX_FILES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model, processor = load_model_and_processor(MODEL_NAME, DTYPE, DEVICE)\n",
    "model.eval()\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset (reuse existing class)\n",
    "dataset = QwenOmniCoTDataset(AUDIO_DIR, processor)\n",
    "print(f\"Found {len(dataset)} files\")\n",
    "for f in dataset.files[:MAX_FILES]:\n",
    "    print(f\"  - {Path(f).name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Prompts for Timestamp Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Timestamp analysis prompt\n",
    "STEP_2_TIMESTAMP_PROMPT = \"\"\"Based on your layer analysis:\n",
    "\n",
    "{step_1_response}\n",
    "\n",
    "Now analyze WHEN each instrument appears. Listen and identify:\n",
    "- When does each instrument first enter?\n",
    "- Are there sections where instruments drop out?\n",
    "- When do instruments return?\n",
    "\n",
    "Format:\n",
    "**Instrument Timeline:**\n",
    "[instrument]: enters at [time], exits at [time], re-enters at [time]\n",
    "...\n",
    "\n",
    "Use timestamps like \"0:00\", \"0:15\", \"1:30\".\"\"\"\n",
    "\n",
    "# Step 3: Final JSON output prompt\n",
    "STEP_3_JSON_PROMPT = \"\"\"Based on your analysis:\n",
    "\n",
    "Layer Analysis:\n",
    "{step_1_response}\n",
    "\n",
    "Timeline:\n",
    "{step_2_response}\n",
    "\n",
    "Output JSON with instruments and timestamps:\n",
    "\n",
    "{{\n",
    "  \"instruments\": [\n",
    "    {{\"name\": \"instrument\", \"layer\": \"background|middle_ground|foreground\", \"timestamps\": [{{\"start\": \"0:00\", \"end\": \"1:30\"}}]}}\n",
    "  ]\n",
    "}}\n",
    "\n",
    "Return ONLY the JSON:\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(conversation, max_new_tokens=512):\n",
    "    \"\"\"Generate response from a conversation.\"\"\"\n",
    "    inputs = processor.apply_chat_template(\n",
    "        conversation,\n",
    "        add_generation_prompt=True,\n",
    "        tokenize=True,\n",
    "        return_tensors=\"pt\",\n",
    "        return_dict=True,\n",
    "    )\n",
    "\n",
    "    # Move to device\n",
    "    inputs = {\n",
    "        k: v.to(DEVICE) if isinstance(v, torch.Tensor) else v for k, v in inputs.items()\n",
    "    }\n",
    "\n",
    "    with torch.no_grad():\n",
    "        text_ids, _ = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            do_sample=False,\n",
    "            return_audio=False,\n",
    "        )\n",
    "\n",
    "    generated_ids = text_ids[:, inputs[\"input_ids\"].shape[1] :]\n",
    "    response = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_with_timestamps(waveform, verbose=True):\n",
    "    \"\"\"\n",
    "    3-step CoT detection:\n",
    "    1. Layer analysis (uses existing CoT prompt)\n",
    "    2. Timestamp analysis\n",
    "    3. Structured JSON output\n",
    "    \"\"\"\n",
    "    # Step 1: Layer analysis (reuse existing conversation builder)\n",
    "    if verbose:\n",
    "        print(\"Step 1: Layer analysis...\")\n",
    "\n",
    "    step_1_conv = QwenOmniCoTDataset.get_conversation(waveform)\n",
    "    step_1_response = generate(step_1_conv, max_new_tokens=512)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"  Done ({len(step_1_response)} chars)\")\n",
    "\n",
    "    # Step 2: Timestamp analysis\n",
    "    if verbose:\n",
    "        print(\"Step 2: Timestamp analysis...\")\n",
    "\n",
    "    step_2_text = STEP_2_TIMESTAMP_PROMPT.format(step_1_response=step_1_response)\n",
    "    step_2_conv = [\n",
    "        QwenOmniCoTDataset.get_system_message(QwenOmniCoTDataset.SYSTEM_PROMPT),\n",
    "        QwenOmniCoTDataset.get_user_message(waveform, step_2_text),\n",
    "    ]\n",
    "    step_2_response = generate(step_2_conv, max_new_tokens=512)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"  Done ({len(step_2_response)} chars)\")\n",
    "\n",
    "    # Step 3: Structured JSON\n",
    "    if verbose:\n",
    "        print(\"Step 3: JSON output...\")\n",
    "\n",
    "    step_3_text = STEP_3_JSON_PROMPT.format(\n",
    "        step_1_response=step_1_response,\n",
    "        step_2_response=step_2_response,\n",
    "    )\n",
    "    step_3_conv = [\n",
    "        QwenOmniCoTDataset.get_system_message(QwenOmniCoTDataset.SYSTEM_PROMPT),\n",
    "        QwenOmniCoTDataset.get_user_message(waveform, step_3_text),\n",
    "    ]\n",
    "    step_3_response = generate(step_3_conv, max_new_tokens=1024)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"  Done ({len(step_3_response)} chars)\")\n",
    "\n",
    "    # Parse JSON\n",
    "    parsed = None\n",
    "    try:\n",
    "        start = step_3_response.find(\"{\")\n",
    "        end = step_3_response.rfind(\"}\") + 1\n",
    "        if start != -1 and end > start:\n",
    "            parsed = json.loads(step_3_response[start:end])\n",
    "    except json.JSONDecodeError:\n",
    "        pass\n",
    "\n",
    "    return {\n",
    "        \"step_1\": step_1_response,\n",
    "        \"step_2\": step_2_response,\n",
    "        \"step_3\": step_3_response,\n",
    "        \"parsed\": parsed,\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get first sample\n",
    "filenames, waveforms, _ = dataset[0]\n",
    "waveform = waveforms[0]\n",
    "filename = Path(filenames[0]).name\n",
    "\n",
    "print(f\"Processing: {filename}\")\n",
    "print(f\"Duration: {len(waveform) / 16000:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 3-step detection\n",
    "result = detect_with_timestamps(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1 output\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 1: LAYER ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(result[\"step_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 output\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 2: TIMESTAMP ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(result[\"step_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3 output\n",
    "print(\"=\" * 60)\n",
    "print(\"STEP 3: JSON OUTPUT\")\n",
    "print(\"=\" * 60)\n",
    "print(result[\"step_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsed output\n",
    "print(\"=\" * 60)\n",
    "print(\"PARSED\")\n",
    "print(\"=\" * 60)\n",
    "if result[\"parsed\"]:\n",
    "    print(json.dumps(result[\"parsed\"], indent=2))\n",
    "else:\n",
    "    print(\"Failed to parse JSON\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Multiple Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process first few files\n",
    "all_results = []\n",
    "\n",
    "for i in range(min(MAX_FILES, len(dataset))):\n",
    "    filenames, waveforms, _ = dataset[i]\n",
    "    filename = Path(filenames[0]).name\n",
    "    waveform = waveforms[0]\n",
    "\n",
    "    print(f\"\\n[{i+1}/{MAX_FILES}] {filename}\")\n",
    "    result = detect_with_timestamps(waveform, verbose=True)\n",
    "    result[\"filename\"] = filename\n",
    "    all_results.append(result)\n",
    "\n",
    "    if result[\"parsed\"]:\n",
    "        n = len(result[\"parsed\"].get(\"instruments\", []))\n",
    "        print(f\"  -> {n} instruments detected\")\n",
    "    else:\n",
    "        print(\"  -> Parse failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for r in all_results:\n",
    "    print(f\"\\n{r['filename']}:\")\n",
    "    if r[\"parsed\"] and \"instruments\" in r[\"parsed\"]:\n",
    "        for inst in r[\"parsed\"][\"instruments\"]:\n",
    "            name = inst.get(\"name\", \"?\")\n",
    "            layer = inst.get(\"layer\", \"?\")\n",
    "            ts = inst.get(\"timestamps\", [])\n",
    "            ts_str = \", \".join(f\"{t.get('start','?')}-{t.get('end','end')}\" for t in ts)\n",
    "            print(f\"  {name} [{layer}]: {ts_str}\")\n",
    "    else:\n",
    "        print(\"  (no parsed output)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
