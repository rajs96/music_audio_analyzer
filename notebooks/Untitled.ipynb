{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6963939d-fe17-4f1c-afed-6a94e7a8147f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "\n",
    "root_path = Path(os.getcwd()).parent\n",
    "sys.path.append(str(root_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4f3c2e8-346b-4dce-a63d-96e2ba97d17e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/Users/rajsingh/Desktop/code/music_audio_analyzer')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6bc59d7-d9ff-4f6e-b4ce-b28318c93262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.instrument_detect.data.qwen_omni import QwenOmniDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87d24df8-8968-4469-9ea5-ddfacf49fcee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Qwen3OmniMoeProcessor\n",
    "MODEL_PATH = \"Qwen/Qwen3-Omni-30B-A3B-Thinking\"\n",
    "processor = Qwen3OmniMoeProcessor.from_pretrained(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5e779e5-7fad-4907-9be0-d0a46e2c0a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = QwenOmniDataset(root_path / \"audio_files\", processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1118aee-bd53-4a9d-9079-1563b3d9b32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/rajsingh/Desktop/code/music_audio_analyzer/audio_files/Red Hot Chili Peppers - Otherside.mp3',\n",
       " '/Users/rajsingh/Desktop/code/music_audio_analyzer/audio_files/Drake - Drew A Picasso.mp3',\n",
       " '/Users/rajsingh/Desktop/code/music_audio_analyzer/audio_files/Chris Brown, Drake - No Guidance (feat. Drake).mp3',\n",
       " \"/Users/rajsingh/Desktop/code/music_audio_analyzer/audio_files/Tom Misch - Isn't She Lovely.mp3\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.files[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5c68baa-12f5-41ab-8b70-d0d329ec749e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[151644,   8948,    271,    286,   1446,    525,   1207,  16948,     11,\n",
       "            264,   4108,   3738,   7881,    553,    279,   1207,  16948,   7909,\n",
       "             11,  54364,   5737,     11,  12875,    315,    817,  46344,  82529,\n",
       "            323,   9124,  11127,     11,    438,   1632,    438,  23163,   1467,\n",
       "            323,   8806,    624,    286,   1446,    525,   1083,    458,   6203,\n",
       "            304,  53526,   1128,  23316,    525,   1660,   6342,    304,    264,\n",
       "           5492,    382,    286,   1446,    686,    387,   2661,    264,   5492,\n",
       "            323,    498,    686,   1184,    311,  11140,   1128,  23316,    525,\n",
       "           1660,   6342,    304,    279,   5492,    624,    286,   3411,    264,\n",
       "           1140,    315,   9069,     11,   1817,    914,    374,    279,    829,\n",
       "            315,    458,  14141,    382,    286,   8278,    990,    279,   2701,\n",
       "           9069,    510,    286,    481,  46289,    198,    286,    481,  21529,\n",
       "            198,    286,    481,   9072,   1889,  34746,    198,    286,    481,\n",
       "          44066,   1889,  34746,    198,    286,    481,  26278,    198,    286,\n",
       "            481,  51289,   3135,    198,    286,    481,   9069,    198,    286,\n",
       "            481,   9956,    198,    286,    481,  46096,    271,    286,  13383,\n",
       "           2550,    220,     16,     25,   2509,   3612,   6237,    516,    364,\n",
       "          63365,   1889,  34746,    516,    364,     79,  13088,    516,    364,\n",
       "             85,    509,   1127,   4432,    286,  13383,   2550,    220,     17,\n",
       "             25,   2509,    580,  34315,   1889,  34746,    516,    364,     79,\n",
       "          13088,    516,    364,     85,    509,   1127,    516,    364,     65,\n",
       "            395,   4432,    286,  13383,   2550,    220,     18,     25,   2509,\n",
       "             79,  13088,    516,    364,     85,    509,   1127,   4432,    260,\n",
       "         151645,    198, 151644,    872,    198, 151669, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675, 151675,\n",
       "         151670, 151645,    198, 151644,  77091,    198]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1]]), 'feature_attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1]], dtype=torch.int32), 'input_features': tensor([[[-0.4676, -0.4676, -0.4676,  ...,  1.0935,  0.7956,  1.0427],\n",
       "         [-0.4676, -0.4676, -0.4676,  ...,  1.1911,  0.8931,  1.1402],\n",
       "         [-0.4676, -0.4676, -0.4676,  ...,  1.2831,  1.0252,  1.2203],\n",
       "         ...,\n",
       "         [-0.4676, -0.4676, -0.4676,  ..., -0.4676, -0.4676, -0.4676],\n",
       "         [-0.4676, -0.4676, -0.4676,  ..., -0.4676, -0.4676, -0.4676],\n",
       "         [-0.4676, -0.4676, -0.4676,  ..., -0.4676, -0.4676, -0.4676]]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0609f27b-c4ca-4dd0-b757-20cdec8e38fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
