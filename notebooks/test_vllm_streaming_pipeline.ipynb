{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test vLLM Streaming Pipeline (Single GPU)\n",
    "\n",
    "Simple test to verify the streaming pipeline works with vLLM on a single GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "import time\n",
    "import hashlib\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from loguru import logger\n",
    "from ray.util.queue import Queue\n",
    "\n",
    "# Shutdown any existing Ray instance\n",
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Ray\n",
    "ray.init(ignore_reinit_error=True)\n",
    "print(f\"Ray initialized: {ray.cluster_resources()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pipeline components\n",
    "from src.streaming_pipeline import (\n",
    "    AgentRayComputeConfig,\n",
    "    AgentStage,\n",
    "    QueueStreamingDatasource,\n",
    "    StreamingDatasourceConfig,\n",
    "    StreamingPipeline,\n",
    ")\n",
    "from src.pipelines.instrument_detection.agents.audio_preprocessor import AudioPreprocessorAgent\n",
    "from src.pipelines.instrument_detection.agents.instrument_detector import InstrumentDetectorAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "MODEL_NAME = \"Qwen/Qwen3-Omni-30B-A3B-Instruct\"  # or your cached model path\n",
    "NUM_TEST_FILES = 50  # Number of audio files to test with\n",
    "WARMUP_TIMEOUT = 300.0  # 5 minutes for model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find audio files\n",
    "audio_dir = Path(\"../audio_files\")\n",
    "audio_files = list(audio_dir.glob(\"*.mp3\"))[:NUM_TEST_FILES]\n",
    "print(f\"Found {len(audio_files)} audio files to test:\")\n",
    "for f in audio_files:\n",
    "    print(f\"  - {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def create_job_row(filepath: Path) -> dict:\n",
    "    \"\"\"Create a job row from an audio file.\"\"\"\n",
    "    audio_bytes = filepath.read_bytes()\n",
    "    return {\n",
    "        \"job_id\": f\"job_{uuid.uuid4().hex[:8]}\",\n",
    "        \"song_id\": f\"song_{uuid.uuid4().hex[:8]}\",\n",
    "        \"song_hash\": hashlib.sha256(audio_bytes).hexdigest()[:16],\n",
    "        \"filename\": filepath.name,\n",
    "        \"audio_bytes\": audio_bytes,\n",
    "    }\n",
    "\n",
    "# Identity function for item_to_row (items are already rows)\n",
    "def identity(x):\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create job queue and datasource\n",
    "job_queue = Queue(maxsize=100)\n",
    "\n",
    "datasource = QueueStreamingDatasource(\n",
    "    queue=job_queue,\n",
    "    item_to_row_fn=identity,\n",
    "    config=StreamingDatasourceConfig(\n",
    "        parallelism=1,\n",
    "        batch_size=1,\n",
    "        batch_timeout=0.5,\n",
    "        poll_interval=0.1,\n",
    "        max_items=NUM_TEST_FILES,\n",
    "    ),\n",
    ")\n",
    "print(\"Datasource created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline stages\n",
    "\n",
    "# Stage 1: Audio Preprocessor (CPU)\n",
    "preprocessor_stage = AgentStage(\n",
    "    agent=AudioPreprocessorAgent(target_sr=16000),\n",
    "    config=AgentRayComputeConfig(\n",
    "        num_actors=2,\n",
    "        batch_size=1,\n",
    "        num_cpus=2.0,\n",
    "        max_concurrency=1,\n",
    "    ),\n",
    "    name=\"AudioPreprocessor\",\n",
    ")\n",
    "\n",
    "# Stage 2: Instrument Detector with vLLM (GPU)\n",
    "detector_stage = AgentStage(\n",
    "    agent=InstrumentDetectorAgent(\n",
    "        model_name=MODEL_NAME,\n",
    "        use_vllm=True,\n",
    "        tensor_parallel_size=1,  # Single GPU\n",
    "        gpu_memory_utilization=0.90,\n",
    "        max_model_len=16384,\n",
    "        max_num_seqs=4,\n",
    "    ),\n",
    "    config=AgentRayComputeConfig(\n",
    "        num_actors=1,\n",
    "        batch_size=1,\n",
    "        num_gpus=1.0,\n",
    "        max_concurrency=1,\n",
    "    ),\n",
    "    name=\"InstrumentDetector\",\n",
    ")\n",
    "\n",
    "print(\"Stages created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "pipeline = StreamingPipeline(\n",
    "    datasource=datasource,\n",
    "    stages=[preprocessor_stage, detector_stage],\n",
    "    name=\"vLLM_InstrumentDetection\",\n",
    ")\n",
    "print(\"Pipeline created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmup the pipeline (this loads the vLLM model)\n",
    "def get_warmup_data():\n",
    "    \"\"\"Create warmup data using first audio file.\"\"\"\n",
    "    warmup_file = audio_files[0]\n",
    "    audio_bytes = warmup_file.read_bytes()\n",
    "    return [{\n",
    "        \"job_id\": \"warmup_001\",\n",
    "        \"song_id\": \"warmup\",\n",
    "        \"song_hash\": \"warmup\",\n",
    "        \"filename\": warmup_file.name,\n",
    "        \"audio_bytes\": audio_bytes,\n",
    "    }]\n",
    "\n",
    "print(f\"Starting warmup (timeout: {WARMUP_TIMEOUT}s)...\")\n",
    "print(\"This will load the vLLM model - may take several minutes...\")\n",
    "warmup_start = time.time()\n",
    "\n",
    "warmup_success = pipeline.warmup(\n",
    "    warmup_data_fn=get_warmup_data,\n",
    "    timeout_seconds=WARMUP_TIMEOUT,\n",
    ")\n",
    "\n",
    "warmup_time = time.time() - warmup_start\n",
    "if warmup_success:\n",
    "    print(f\"Warmup complete in {warmup_time:.1f}s - pipeline ready!\")\n",
    "else:\n",
    "    print(f\"Warmup failed or timed out after {warmup_time:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submit jobs to the queue\n",
    "print(f\"Submitting {len(audio_files)} jobs...\")\n",
    "for i, audio_file in enumerate(audio_files):\n",
    "    row = create_job_row(audio_file)\n",
    "    job_queue.put(row)\n",
    "    print(f\"  [{i+1}/{len(audio_files)}] Submitted: {row['filename']}\")\n",
    "    time.sleep(0.1)  # Small delay between submissions\n",
    "\n",
    "print(f\"All {len(audio_files)} jobs submitted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stream results\n",
    "results = []\n",
    "start_time = time.time()\n",
    "\n",
    "print(\"Streaming results...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for batch in pipeline.stream(batch_size=1):\n",
    "    if not batch:\n",
    "        continue\n",
    "    \n",
    "    # Convert batch to list of dicts\n",
    "    keys = list(batch.keys())\n",
    "    if not keys:\n",
    "        continue\n",
    "        \n",
    "    n_items = len(batch[keys[0]])\n",
    "    for i in range(n_items):\n",
    "        result = {k: batch[k][i] for k in keys}\n",
    "        results.append(result)\n",
    "        \n",
    "        elapsed = time.time() - start_time\n",
    "        \n",
    "        if result.get(\"error\"):\n",
    "            print(f\"[{elapsed:.1f}s] {result['filename']} -> ERROR: {result['error']}\")\n",
    "        else:\n",
    "            instruments = result.get('instruments', [])\n",
    "            print(f\"[{elapsed:.1f}s] {result['filename']} -> {instruments}\")\n",
    "    \n",
    "    if len(results) >= NUM_TEST_FILES:\n",
    "        print(\"-\" * 60)\n",
    "        print(f\"All {NUM_TEST_FILES} results received!\")\n",
    "        break\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nTotal streaming time: {total_time:.1f}s\")\n",
    "print(f\"Average per file: {total_time / len(results):.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESULTS SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "successful = [r for r in results if not r.get(\"error\")]\n",
    "failed = [r for r in results if r.get(\"error\")]\n",
    "\n",
    "print(f\"Total: {len(results)}\")\n",
    "print(f\"Successful: {len(successful)}\")\n",
    "print(f\"Failed: {len(failed)}\")\n",
    "\n",
    "print(\"\\nDetailed results:\")\n",
    "for r in results:\n",
    "    if r.get(\"error\"):\n",
    "        print(f\"  - {r['filename']}: ERROR - {r['error']}\")\n",
    "    else:\n",
    "        print(f\"  - {r['filename']}: {r.get('instruments', [])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup\n",
    "pipeline.stop()\n",
    "ray.shutdown()\n",
    "print(\"Cleanup complete\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
