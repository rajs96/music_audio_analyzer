{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eec75dd-0a2c-4dd2-811e-265b103fc5b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-31 03:50:25,397\tINFO worker.py:1998 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32m127.0.0.1:8267 \u001b[39m\u001b[22m\n",
      "2025-12-31 03:50:25,404\tINFO packaging.py:392 -- Ignoring upload to cluster for these files: [PosixPath('/Users/rajsingh/Desktop/code/music_audio_analyzer/.gitignore')]\n",
      "2025-12-31 03:50:25,449\tINFO packaging.py:691 -- Creating a file package for local module '/Users/rajsingh/Desktop/code/music_audio_analyzer'.\n",
      "2025-12-31 03:50:25,450\tINFO packaging.py:392 -- Ignoring upload to cluster for these files: [PosixPath('/Users/rajsingh/Desktop/code/music_audio_analyzer/.gitignore')]\n",
      "2025-12-31 03:50:25,475\tINFO packaging.py:463 -- Pushing file package 'gcs://_ray_pkg_1f023727ce2b90eb.zip' (0.42MiB) to Ray cluster...\n",
      "2025-12-31 03:50:25,476\tINFO packaging.py:476 -- Successfully pushed file package 'gcs://_ray_pkg_1f023727ce2b90eb.zip'.\n",
      "/Users/rajsingh/.pyenv/versions/3.10.12/envs/stem-splitter-app-env/lib/python3.10/site-packages/ray/_private/worker.py:2046: FutureWarning: Tip: In future versions of Ray, Ray will no longer override accelerator visible devices env var if num_gpus=0 or num_gpus=None (default). To enable this behavior and turn off this error message, set RAY_ACCEL_ENV_VAR_OVERRIDE_ON_ZERO=0\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: Red Hot Chili Peppers - Otherside.mp3\n",
      "Audio size: 8021583 bytes\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-31 03:50:29.321\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.streaming_pipeline.streaming_component\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m146\u001b[0m - \u001b[1mRay Data streaming config: preserve_order=False\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-12-31 03:50:31.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.streaming_pipeline.streaming_component\u001b[0m:\u001b[36mbuild\u001b[0m:\u001b[36m155\u001b[0m - \u001b[1mAdding stage: DirectBytesTest\u001b[0m\n",
      "2025-12-31 03:50:31,167\tINFO logging.py:397 -- Registered dataset logger for dataset dataset_1_0\n",
      "2025-12-31 03:50:31,174\tINFO streaming_executor.py:178 -- Starting execution of Dataset dataset_1_0. Full logs are in /tmp/ray/session_2025-12-31_03-50-22_342761_9140/logs/ray-data\n",
      "2025-12-31 03:50:31,174\tINFO streaming_executor.py:179 -- Execution plan of Dataset dataset_1_0: InputDataBuffer[Input] -> TaskPoolMapOperator[ReadQueueStreaming] -> ActorPoolMapOperator[MapBatches(AgentCallable)]\n",
      "2025-12-31 03:50:31,189\tINFO streaming_executor.py:686 -- [dataset]: A new progress UI is available. To enable, set `ray.data.DataContext.get_current().enable_rich_progress_bars = True` and `ray.data.DataContext.get_current().use_ray_tqdm = False`.\n",
      "2025-12-31 03:50:31,189\tINFO progress_bar.py:155 -- Progress bar disabled because stdout is a non-interactive terminal.\n",
      "2025-12-31 03:50:31,190\tWARNING resource_manager.py:136 -- ⚠️  Ray's object store is configured to use only 22.8% of available memory (2.0GiB out of 8.8GiB total). For optimal Ray Data performance, we recommend setting the object store to at least 50% of available memory. You can do this by setting the 'object_store_memory' parameter when calling ray.init() or by setting the RAY_DEFAULT_OBJECT_STORE_MEMORY_PROPORTION environment variable.\n",
      "2025-12-31 03:50:31,190\tWARNING default_actor_autoscaler.py:236 -- ⚠️  Actor Pool configuration of the ActorPoolMapOperator[MapBatches(AgentCallable)] will not allow it to scale up: configured utilization threshold (200.0%) couldn't be reached with configured max_concurrency=1 and max_tasks_in_flight_per_actor=1 (max utilization will be max_tasks_in_flight_per_actor / max_concurrency = 100%)\n",
      "2025-12-31 03:50:31,378\tINFO progress_bar.py:213 -- === Ray Data Progress {ReadQueueStreaming->SplitBlocks(200)} ===\n",
      "2025-12-31 03:50:31,379\tINFO progress_bar.py:215 -- ReadQueueStreaming->SplitBlocks(200): Tasks: 1; Actors: 0; Queued blocks: 0 (0.0B); Resources: 1.0 CPU, 3.0MiB object store: Progress Completed 0 / ?\n",
      "2025-12-31 03:50:31,380\tINFO progress_bar.py:213 -- === Ray Data Progress {MapBatches(AgentCallable)} ===\n",
      "2025-12-31 03:50:31,380\tINFO progress_bar.py:215 -- MapBatches(AgentCallable): Tasks: 0; Actors: 1 (running=0, restarting=0, pending=1); Queued blocks: 0 (0.0B); Resources: 0.0 CPU, 0.0B object store; [all objects local]: Progress Completed 0 / ?\n",
      "2025-12-31 03:50:31,380\tINFO progress_bar.py:213 -- === Ray Data Progress {Running Dataset} ===\n",
      "2025-12-31 03:50:31,381\tINFO progress_bar.py:215 -- Running Dataset: dataset_1_0. Active & requested resources: 0/10 CPU, 0.0B/1.0GiB object store (pending: 1 CPU): Progress Completed 0 / ?\n",
      "\u001b[36m(MapWorker(MapBatches(AgentCallable)) pid=9181)\u001b[0m 2025-12-31 03:50:33.211 | INFO     | src.streaming_pipeline.agent:__init__:301 - AgentCallable initialized: FunctionAgent\n",
      "\u001b[36m(ReadQueueStreaming->SplitBlocks(200) pid=9183)\u001b[0m 2025-12-31 03:50:33.301 | INFO     | src.streaming_pipeline.streaming_datasource:make_block_generator:247 - Generator started. queue=<ray.util.queue.Queue object at 0x115dc84f0>, max_items=1\n",
      "\u001b[36m(ReadQueueStreaming->SplitBlocks(200) pid=9183)\u001b[0m 2025-12-31 03:50:33.309 | DEBUG    | src.streaming_pipeline.streaming_datasource:make_block_generator:281 - Got item #0\n",
      "\u001b[36m(ReadQueueStreaming->SplitBlocks(200) pid=9183)\u001b[0m 2025-12-31 03:50:33.312 | DEBUG    | src.streaming_pipeline.streaming_datasource:make_block_generator:334 - Yielding batch with 1 rows, total_read=1\n",
      "\u001b[36m(ReadQueueStreaming->SplitBlocks(200) pid=9183)\u001b[0m 2025-12-31 03:50:33.323 | INFO     | src.streaming_pipeline.streaming_datasource:make_block_generator:260 - Reached max_items limit (1)\n",
      "\u001b[36m(ReadQueueStreaming->SplitBlocks(200) pid=9183)\u001b[0m 2025-12-31 03:50:33.323 | INFO     | src.streaming_pipeline.streaming_datasource:make_block_generator:345 - StreamingDatasource reader exiting, read 1 items\n",
      "2025-12-31 03:50:33,344\tINFO streaming_executor.py:304 -- ✔️  Dataset dataset_1_0 execution finished in 2.17 seconds\n",
      "\u001b[32m2025-12-31 03:50:33.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.streaming_pipeline.streaming_datasource\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m180\u001b[0m - \u001b[1mStreamingDatasource stop requested\u001b[0m\n",
      "\u001b[32m2025-12-31 03:50:33.346\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36msrc.streaming_pipeline.streaming_component\u001b[0m:\u001b[36mstop\u001b[0m:\u001b[36m286\u001b[0m - \u001b[1mPipeline DebugTest stopped\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUCCESS! Got result: {'job_id': array(['test_001'], dtype=object), 'filename': array(['Red Hot Chili Peppers - Otherside.mp3'], dtype=object), 'audio_size': array([8021583]), 'error': array([nan], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "import ray\n",
    "import time\n",
    "import hashlib\n",
    "from pathlib import Path\n",
    "from ray.util.queue import Queue\n",
    "\n",
    "ray.shutdown()\n",
    "time.sleep(1)\n",
    "\n",
    "PROJECT_ROOT = \"/Users/rajsingh/Desktop/code/music_audio_analyzer\"\n",
    "ray.init(\n",
    "    runtime_env={\n",
    "        \"working_dir\": PROJECT_ROOT,\n",
    "        \"excludes\": [\"*.mp3\", \"*.wav\", \"audio_files/\", \".git/\", \"__pycache__/\"],\n",
    "        \"env_vars\": {\"_CACHE_BUST\": str(time.time())},\n",
    "    }\n",
    ")\n",
    "\n",
    "from src.streaming_pipeline import (\n",
    "    FunctionAgent,\n",
    "    AgentRayComputeConfig,\n",
    "    AgentStage,\n",
    "    QueueStreamingDatasource,\n",
    "    StreamingDatasourceConfig,\n",
    "    StreamingPipeline,\n",
    ")\n",
    "\n",
    "\n",
    "# Test function - receives audio_bytes directly, NOT an ObjectRef\n",
    "def test_audio_direct(items):\n",
    "    from loguru import logger\n",
    "\n",
    "    results = []\n",
    "    for item in items:\n",
    "        logger.info(f\"Processing: {item.get('filename', 'unknown')}\")\n",
    "\n",
    "        # audio_bytes is passed directly, not as ObjectRef\n",
    "        audio_bytes = item.get(\"audio_bytes\")\n",
    "        if audio_bytes:\n",
    "            logger.info(f\"Got {len(audio_bytes)} bytes directly\")\n",
    "            results.append(\n",
    "                {\n",
    "                    \"job_id\": item[\"job_id\"],\n",
    "                    \"filename\": item[\"filename\"],\n",
    "                    \"audio_size\": len(audio_bytes),\n",
    "                    \"error\": None,\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            logger.error(\"No audio_bytes!\")\n",
    "            results.append(\n",
    "                {\n",
    "                    \"job_id\": item[\"job_id\"],\n",
    "                    \"filename\": item[\"filename\"],\n",
    "                    \"audio_size\": 0,\n",
    "                    \"error\": \"No audio_bytes\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "# Setup with ONE audio file - pass bytes DIRECTLY, not ObjectRef\n",
    "AUDIO_DIR = Path(PROJECT_ROOT) / \"audio_files\"\n",
    "audio_file = list(AUDIO_DIR.glob(\"*.mp3\"))[0]\n",
    "print(f\"Using: {audio_file.name}\")\n",
    "\n",
    "audio_bytes = audio_file.read_bytes()\n",
    "print(f\"Audio size: {len(audio_bytes)} bytes\")\n",
    "\n",
    "job_queue = Queue(maxsize=10)\n",
    "job_queue.put(\n",
    "    {\n",
    "        \"job_id\": \"test_001\",\n",
    "        \"filename\": audio_file.name,\n",
    "        \"audio_bytes\": audio_bytes,  # Pass bytes directly, NOT ray.put()\n",
    "    }\n",
    ")\n",
    "\n",
    "datasource = QueueStreamingDatasource(\n",
    "    queue=job_queue,\n",
    "    item_to_row_fn=lambda x: x,\n",
    "    config=StreamingDatasourceConfig(batch_size=1, batch_timeout=1.0, max_items=1),\n",
    ")\n",
    "\n",
    "stage = AgentStage(\n",
    "    agent=FunctionAgent(process_fn=test_audio_direct),\n",
    "    config=AgentRayComputeConfig(num_actors=1, batch_size=1),\n",
    "    name=\"DirectBytesTest\",\n",
    ")\n",
    "\n",
    "pipeline = StreamingPipeline(datasource=datasource, stages=[stage], name=\"DebugTest\")\n",
    "\n",
    "print(\"Starting pipeline...\")\n",
    "try:\n",
    "    for batch in pipeline.stream(batch_size=1):\n",
    "        print(f\"SUCCESS! Got result: {batch}\")\n",
    "        break\n",
    "except Exception as e:\n",
    "    print(f\"ERROR: {e}\")\n",
    "finally:\n",
    "    pipeline.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
